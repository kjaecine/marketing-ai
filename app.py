import streamlit as st
import pandas as pd
from groq import Groq
import requests
from bs4 import BeautifulSoup
import io
import re

# --- ğŸ”’ [API í‚¤ ì„¤ì •] ---
part1 = "gsk_lIDRWFZfRKNye7Il5egq"
part2 = "WGdyb3FY5WLFI3NtD9NB70RLy6uk4Mce"
FIXED_API_KEY = part1 + part2
FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Deep Learning Fix)")
st.markdown("ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸í•˜ëŠ” **ë””ë²„ê¹… ëª¨ë“œ**ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY.startswith("gsk_"):
        st.success("âœ… Groq API Key ì—°ê²°ë¨")
    else:
        st.error("API Key ì„¤ì • ì˜¤ë¥˜")
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹°: í…ìŠ¤íŠ¸ ì²­ì†Œ ---
def clean_text_force_korean(text):
    # í•œì/ì¼ë³¸ì–´ ì‚­ì œ
    pattern = re.compile(r'[\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]+')
    cleaned_text = pattern.sub('', text)
    return cleaned_text

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: Groq í˜¸ì¶œ ---
def generate_copy_groq(api_key, context_examples, keyword, info, user_config):
    client = Groq(api_key=api_key)
    
    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    # ì°¸ê³  ë°ì´í„°ê°€ ë¹„ì—ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê°•ì œ í˜ë¥´ì†Œë‚˜ ì£¼ì…
    if not context_examples:
        context_examples = """
        (Example 1)
        Title: Xì™€ì˜ ì¬íšŒ, ì‹¬ì¥ ë©ëŠ” ì¤„..
        Body: ë‚´ ëˆˆì•ì— ë‚˜íƒ€ë‚œ ì „ë‚¨ì¹œ, í”ë“¤ë¦¬ëŠ” ë™ê³µ ã„·ã„· #í™˜ìŠ¹ì—°ì•  #ì¬íšŒ
        
        (Example 2)
        Title: ê±°ì§“ë§ íƒì§€ê¸° ê²°ê³¼ ì¶©ê²© ğŸ˜±
        Body: "ë„ˆ ì•„ì§ ë‚˜ ì¢‹ì•„í•´?" ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì€? #ê³¼ëª°ì… #ë„íŒŒë¯¼
        """

    prompt = f"""
    Role: You are a Viral Marketing Copywriter for a Dating Reality Show (like Transit Love/EXchange).
    
    [YOUR MISSION]
    Create 10 marketing messages for '{keyword}'.
    
    [CRITICAL INSTRUCTION: STYLE TRANSFER]
    You MUST analyze the [Reference Examples] below. 
    Copy their **sentence structure**, **slang usage**, **emotional tone**, and **emoji patterns**.
    Do NOT write polite or educational text. Write like a gossiping friend or a provocative ad.

    [Reference Examples (LEARN FROM HERE)]
    {context_examples}
    
    [Trend Info]
    {info}

    [User Request]
    {custom_instruction}

    [Constraints]
    1. **Language:** Korean (Hangul) ONLY. No Hanja.
    2. **Format:** CSV with '|' separator.
    3. **Columns:** ë¶„ë¥˜|ìº í˜ì¸|íƒ€ê²Ÿ|ì½˜í…ì¸ |ì œëª©|ë‚´ìš©
    4. **Tone:** Provocative, Emotional, "Dopamine-inducing", Short slang (e.g., ã„·ã„·, ã… ã… , ã…‹ã…‹).
    5. **Length:** Title < 20 chars, Body < 40 chars.

    **Output ONLY the CSV data.**
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.9, # ì°½ì˜ì„± ìµœëŒ€ì¹˜ (ìê·¹ì ì¸ ë¬¸êµ¬ë¥¼ ìœ„í•´)
            max_tokens=2048,
            top_p=1,
            stream=False,
            stop=None,
        )
        return completion.choices[0].message.content, "llama-3.3-70b"

    except Exception as e:
        raise Exception(f"Groq API ì˜¤ë¥˜: {str(e)}")

# --- (ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ë“¤ - ì‹œíŠ¸ ë°ì´í„° ê°€ê³µ ê°•í™”) ---

def get_sheet_data_as_examples(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        
        # ë°ì´í„° ì½ê¸° (ì—ëŸ¬ ë¬´ì‹œ ëª¨ë“œ)
        df = pd.read_csv(url, encoding='utf-8', on_bad_lines='skip', engine='python')
        
        if df.empty: return None, pd.DataFrame()

        # NaN ì œê±°
        df = df.fillna("")
        
        # 'ì œëª©'ê³¼ 'ë‚´ìš©' ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆìœ¼ë©´ ê·¸ê²ƒ ìœ„ì£¼ë¡œ í•™ìŠµ
        # ì»¬ëŸ¼ëª…ì„ ëª» ì°¾ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì»¬ëŸ¼ ì¸ë±ìŠ¤ë¡œ ì ‘ê·¼ ì‹œë„
        title_col = None
        body_col = None

        for col in df.columns:
            if 'ì œëª©' in col: title_col = col
            if 'ë‚´ìš©' in col: body_col = col
            
        examples = ""
        # ì œëª©/ë‚´ìš© ì»¬ëŸ¼ì„ ì°¾ì•˜ìœ¼ë©´ ê·¸ê²ƒë§Œ ë½‘ì•„ì„œ ì˜ˆì‹œë¡œ ë§Œë“¦ (AIê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ)
        if title_col and body_col:
            # í•™ìŠµìš©ìœ¼ë¡œ 20ê°œ ìƒ˜í”Œë§
            sample_df = df.sample(min(20, len(df)))
            for _, row in sample_df.iterrows():
                examples += f"Title: {row[title_col]}\nBody: {row[body_col]}\n---\n"
        else:
            # ì»¬ëŸ¼ ëª» ì°¾ìœ¼ë©´ ê·¸ëƒ¥ ì „ì²´ í…ìŠ¤íŠ¸ë¡œ
            sample_df = df.sample(min(20, len(df)))
            examples = sample_df.to_string(index=False)

        return examples, df # í•™ìŠµìš© í…ìŠ¤íŠ¸ì™€ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
    except Exception as e:
        print(f"Sheet Error: {e}")
        return None, pd.DataFrame()

def get_naver_search(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=1"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        news = []
        for item in soup.select(".news_area")[:3]: # ë‰´ìŠ¤ 3ê°œë§Œ (ë…¸ì´ì¦ˆ ê°ì†Œ)
            title = item.select_one('.news_tit').get_text()
            news.append(f"- {title}")
        return "\n".join(news) if news else ""
    except: return ""

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")
col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±, ì „ì• ì¸ ë¯¸ë ¨")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: ìê·¹ì ìœ¼ë¡œ, ë§µê²Œ")

# --- ë°ì´í„° í™•ì¸ìš© ì„¹ì…˜ (ì‚¬ìš©ìê°€ ì§ì ‘ í™•ì¸ ê°€ëŠ¥) ---
with st.expander("ğŸ“Š ì‹œíŠ¸ ë°ì´í„° ì—°ê²° ìƒíƒœ í™•ì¸ (í´ë¦­)", expanded=False):
    if st.button("ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸"):
        examples, raw_df = get_sheet_data_as_examples(sheet_id_input, sheet_gid_input)
        if not raw_df.empty:
            st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ì´ {len(raw_df)}í–‰ì„ ì½ì—ˆìŠµë‹ˆë‹¤.")
            st.dataframe(raw_df.head(5)) # ìƒìœ„ 5ê°œ ë³´ì—¬ì¤Œ
            st.text_area("ğŸ¤– AIì—ê²Œ ë“¤ì–´ê°€ëŠ” í•™ìŠµ ë°ì´í„° ì˜ˆì‹œ", examples, height=200)
        else:
            st.error("âŒ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‹œíŠ¸ ê¶Œí•œì´ë‚˜ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        status_box.write("ğŸ” ìµœì‹  íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘...")
        search_info = get_naver_search(keyword)
        
        status_box.write("ğŸ“š ì‹œíŠ¸ ë°ì´í„° 'ë§íˆ¬' ì¶”ì¶œ ì¤‘...")
        # ì—¬ê¸°ì„œ ë°ì´í„°ë¥¼ í™•ì‹¤í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        context_examples, _ = get_sheet_data_as_examples(sheet_id_input, sheet_gid_input)
        
        if not context_examples:
            status_box.write("âš ï¸ ì‹œíŠ¸ í•™ìŠµ ì‹¤íŒ¨! 'ê¸°ë³¸ ë„íŒŒë¯¼ ëª¨ë“œ'ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        
        status_box.write("âš¡ Groq ì—”ì§„ìœ¼ë¡œ ì¹´í”¼ë¼ì´íŒ… ì¤‘...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            # ìƒì„±
            raw_text, used_model = generate_copy_groq(FIXED_API_KEY, context_examples, keyword, search_info, config)
            
            # CSV íŒŒì‹±
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            if '|' in clean_csv:
                lines = clean_csv.split('\n')
                csv_lines = [line for line in lines if '|' in line]
                clean_csv = '\n'.join(csv_lines)

            df = pd.read_csv(io.StringIO(clean_csv), sep='|')
            
            # ë²•ì  ë¬¸êµ¬ & ê¸€ììˆ˜ & í•œì í•„í„°
            if any('ë‚´ìš©' in c for c in df.columns):
                content_col = [c for c in df.columns if 'ë‚´ìš©' in c][0] 
                
                def final_clean(text):
                    text = clean_text_force_korean(str(text))
                    text = text.strip()
                    # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¦„
                    if len(text) > 40: text = text[:38] + ".."
                    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"

                df[content_col] = df[content_col].apply(final_clean)
            
            status_box.update(label=f"âœ… ì™„ë£Œ!", state="complete", expanded=False)
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
