import streamlit as st
import pandas as pd
import google.generativeai as genai
import requests
import io
import re
import xml.etree.ElementTree as ET # RSS íŒŒì‹±ìš©

# --- ğŸ”’ [ì‚¬ìš©ì ê³ ì • ì„¤ì •] ---
FIXED_API_KEY = 'AIzaSyA1HhzAK2y_TCKjb1tG3M7GHnmC5uKh4WM'
FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

# --- ğŸ¨ í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="ğŸ’", layout="wide")
st.title("ğŸ’ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Google News RSS)")
st.markdown("ğŸš€ **Gemma 3 27B** + **êµ¬ê¸€ ë‰´ìŠ¤ RSS(ë¬´ì¤‘ë‹¨ ê²€ìƒ‰)** + **ì •ë°€ íŒ¨í„´ í•™ìŠµ**")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def get_google_news_rss(keyword):
    """
    êµ¬ê¸€ ë‰´ìŠ¤ RSS í”¼ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ì´ ë°©ì‹ì€ í¬ë¡¤ë§ ì°¨ë‹¨ì´ ì—†ìœ¼ë©° ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.
    """
    try:
        # êµ¬ê¸€ ë‰´ìŠ¤ í•œêµ­ ì„œë²„ RSS URL
        url = f"https://news.google.com/rss/search?q={keyword}&hl=ko&gl=KR&ceid=KR:ko"
        response = requests.get(url, timeout=5)
        
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            news_list = []
            
            # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ ì•„ì´í…œ íŒŒì‹±
            count = 0
            for item in root.findall('./channel/item'):
                if count >= 5: break
                title = item.find('title').text
                # RSS descriptionì€ HTML íƒœê·¸ê°€ ì„ì—¬ìˆì–´ ì§€ì €ë¶„í•˜ë¯€ë¡œ ì œëª© ìœ„ì£¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                # ë§ˆì¼€íŒ… ì¹´í”¼ìš©ìœ¼ë¡œëŠ” ì œëª©ì˜ í‚¤ì›Œë“œë§Œìœ¼ë¡œë„ ì¶©ë¶„í•©ë‹ˆë‹¤.
                news_list.append(f"- {title}")
                count += 1
            
            if not news_list:
                return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ í‚¤ì›Œë“œ í™•ì¸ í•„ìš”)"
                
            return "\n".join(news_list)
        else:
            return f"ë‰´ìŠ¤ ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (Code: {response.status_code})"
            
    except Exception as e:
        return f"ë‰´ìŠ¤ ê²€ìƒ‰ ì—ëŸ¬: {str(e)}"

def get_sheet_data(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        df = pd.read_csv(url, encoding='utf-8', on_bad_lines='skip')
        if df.empty: return None
        # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìµœì‹  50ê°œë§Œ
        if len(df) > 50: df = df.tail(50)
        return df.to_markdown(index=False)
    except:
        return None

def generate_plan_gemma_fixed(api_key, context, keyword, purpose, info, user_config):
    genai.configure(api_key=api_key)
    
    # [ê³ ì •] ì‚¬ìš©ì ì§€ì • ëª¨ë¸
    target_model = 'gemma-3-27b-it'
    
    try:
        model = genai.GenerativeModel(target_model)
        
        custom_instruction = ""
        if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
        # ìº í˜ì¸ ëª©ì  ë°˜ì˜
        if purpose: custom_instruction += f"- ìº í˜ì¸ ëª©ì (ëŒ€ë¶„ë¥˜): {purpose}\n"
        if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

        if not context: context = "í•™ìŠµ ë°ì´í„° ì—†ìŒ."

        # í”„ë¡¬í”„íŠ¸: ì‚¬ìš©ìì˜ êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­(ëŒ€ë¶„ë¥˜ ë§¤í•‘, ê¸€ììˆ˜) ì™„ë²½ ë°˜ì˜
        prompt = f"""
        Role: Senior Viral Marketing Copywriter (Korea).
        
        [Mission]
        1. **PATTERN LEARNING (CRITICAL):** - Reference Data Source: Google Sheet provided below.
           - **Pattern Logic:**
             - 'ëŒ€ë¶„ë¥˜' column = **Campaign Objective** (e.g., ì‹œì²­ìœ ë„, ì¬ì‹œì²­).
             - 'ì¶”ì²œ ì½˜í…ì¸ ' column = **Content Topic** (e.g., {keyword}).
             - 'ì œëª©/ë‚´ìš©' columns = The output style you must mimic.
           - **Task:** Analyze how the tone and angle change based on the 'Campaign Objective' ({purpose}). Apply that specific pattern to the current request.
        
        2. **TASK:** Create 10 marketing messages for '{keyword}' with the objective '{purpose}'.
        
        3. **STRICT LENGTH CONSTRAINTS (CALCULATE CAREFULLY):**
           - **Title:** **20~25 characters (EXCLUDING SPACES).** - Make it catchy and complete. Not too short.
           - **Body:** **40~45 characters (EXCLUDING SPACES).**
             - **IMPORTANT:** Do NOT include `(ê´‘ê³ )` or `*ìˆ˜ì‹ ê±°ë¶€` in your output text.
             - I will add `(ê´‘ê³ )`(4 chars) and `*ìˆ˜ì‹ ê±°ë¶€...`(11 chars) programmatically.
             - So, your generated body text must be around 40-45 chars to keep the TOTAL length under 60 chars.

        4. **CONTENT SOURCE:** Use the [News/Trends Info] below to include real facts (names, dates, events).

        [Reference Data (Sheet)]
        {context}

        [News/Trends Info (Real-time)]
        {info}

        [User Request]
        {custom_instruction}

        [Output Format]
        ëŒ€ë¶„ë¥˜|ìº í˜ì¸ëª©ì |íƒ€ê²Ÿ|ì½˜í…ì¸ ëª…|ì œëª©|ë‚´ìš©
        (CSV format with '|' separator. NO markdown.)
        """
        
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        response = model.generate_content(prompt, safety_settings=safety_settings)
        return response.text, target_model

    except Exception as e:
        raise Exception(f"ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨ ({target_model}): {str(e)}")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.success("âœ… API Key ì ìš©ë¨")
    st.info("âš¡ ëª¨ë¸: **gemma-3-27b-it** (ê³ ì •)")

    st.divider()
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ–¥ï¸ ë©”ì¸ í™”ë©´ ---

col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ (ì½˜í…ì¸ ëª…)", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    purpose = st.text_input("ğŸ¯ ìº í˜ì¸ ëª©ì  (ëŒ€ë¶„ë¥˜)", placeholder="ì˜ˆ: ì‹œì²­ìœ ë„, ì¬ì‹œì²­, ëŸ°ì¹­ì•Œë¦¼")

col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ‘¥ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: í˜¸ê¸°ì‹¬ ìê·¹, íŒ©íŠ¸ ê°•ì¡°")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("í™ë³´í•  ì£¼ì œ(ì½˜í…ì¸ ëª…)ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not purpose:
        st.warning("ìº í˜ì¸ ëª©ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        # 1. ê²€ìƒ‰ (Google News RSS)
        status_box.write(f":mag: '{keyword}' êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ (RSS)...")
        search_info = get_google_news_rss(keyword)
        
        if "ì—†ìŒ" in search_info or "ì—ëŸ¬" in search_info:
             status_box.write(f"âš ï¸ ê²€ìƒ‰ ìƒíƒœ: {search_info}")
        else:
             status_box.write("âœ… ìµœì‹  íŠ¸ë Œë“œ ì •ë³´ í™•ë³´!")
             with st.expander("ë‰´ìŠ¤ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                 st.text(search_info)
        
        # 2. ì‹œíŠ¸
        status_box.write(":books: êµ¬ê¸€ ì‹œíŠ¸ í•™ìŠµ ì¤‘ (íŒ¨í„´ ë¶„ì„)...")
        sheet_data = get_sheet_data(sheet_id_input, sheet_gid_input)
        
        # 3. ìƒì„±
        status_box.write(f":robot_face: Gemma 3 (27B) ì—”ì§„ ê°€ë™...")
        try:
            config = {"target": target, "note": note}
            
            raw_text, used_model = generate_plan_gemma_fixed(FIXED_API_KEY, sheet_data, keyword, purpose, search_info, config)
            
            # íŒŒì‹±
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            df = pd.read_csv(io.StringIO(clean_csv), sep='|')
            
            # í›„ì²˜ë¦¬: ë²•ì  ë¬¸êµ¬ ì¶”ê°€
            content_cols = [c for c in df.columns if 'ë‚´ìš©' in c]
            if content_cols:
                content_col = content_cols[0]
                def final_formatter(text):
                    text = str(text).replace("(ê´‘ê³ )", "").replace("*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½", "").strip()
                    # ë²•ì  ë¬¸êµ¬ ê²°í•©
                    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"
                
                df[content_col] = df[content_col].apply(final_formatter)
            
            status_box.update(label=f":white_check_mark: ì™„ë£Œ!", state="complete", expanded=False)
            
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(":inbox_tray: ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label=":x: ì˜¤ë¥˜", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
