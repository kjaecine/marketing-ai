import streamlit as st
import pandas as pd
from groq import Groq
import requests
from bs4 import BeautifulSoup
import io
import re
import csv
import random

# --- ğŸ”’ [ì‚¬ìš©ì ê³ ì • ì„¤ì •] ---
# Groq API í‚¤ (ì‚¬ìš©ìë‹˜ í‚¤ ì ìš©ë¨)
part1 = "gsk_lIDRWFZfRKNye7Il5egq"
part2 = "WGdyb3FY5WLFI3NtD9NB70RLy6uk4Mce"
FIXED_API_KEY = part1 + part2

FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Groq High-End Ver)")
st.markdown("ë„¤ì´ë²„ ë³´ì•ˆ ìš°íšŒ + ë°ì´í„° í† í° ìµœì í™” + Geminiê¸‰ í’ˆì§ˆ íŠœë‹")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY.startswith("gsk_"):
        st.success("âœ… Groq API Key ì—°ê²°ë¨")
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹°: í…ìŠ¤íŠ¸ ì •ì œ (ë²•ì  ë¬¸êµ¬ & ê¸€ììˆ˜ ì œì–´) ---
def clean_and_format_final(text):
    if not isinstance(text, str): return str(text)
    
    # 1. ì¤‘ë³µ ë¬¸êµ¬ ì œê±°
    text = text.replace("(ê´‘ê³ )", "").replace("*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½", "")
    text = text.replace('"', '').replace("'", "")
    
    # 2. ì™¸êµ­ì–´(ë² íŠ¸ë‚¨ì–´, í•œì ë“±) ê°•ë ¥ ì°¨ë‹¨
    # í•œê¸€, ì˜ì–´, ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸, ì´ëª¨ì§€ë§Œ ë‚¨ê¹€
    foreign_pattern = re.compile(r'[\u4E00-\u9FFF\u00C0-\u024F\u1E00-\u1EFF\u0600-\u06FF\u0400-\u04FF]+')
    text = foreign_pattern.sub('', text)
    
    # 3. ê³µë°± ì •ë¦¬
    text = text.strip()
    
    # 4. ë²•ì  ë¬¸êµ¬ ë¶€ì°©
    # (ê´‘ê³ ) [4ì] + ê³µë°± + ë³¸ë¬¸ + ì¤„ë°”ê¿ˆ + *ìˆ˜ì‹ ê±°ë¶€... [11ì] = ê³ ì • ì•½ 17ì
    # ë³¸ë¬¸ì´ 45ì ë‚´ì™¸ë©´ ì´ 62ì ë‹¬ì„±
    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ (í—¤ë” ìœ„ì¥ ê¸°ìˆ  ì ìš©) ---
def get_naver_search(keyword):
    """
    ë„¤ì´ë²„ ë´‡ ì°¨ë‹¨ì„ ëš«ê¸° ìœ„í•´ 'ë‚˜ëŠ” ì‚¬ëŒì…ë‹ˆë‹¤'ë¼ëŠ” ì¦ëª…ì„œ(Header)ë¥¼ ì œì¶œí•©ë‹ˆë‹¤.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.naver.com/'
    }
    
    try:
        # ë‰´ìŠ¤ íƒ­ ê²€ìƒ‰
        url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sort=1"
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        news_list = []
        # ë‰´ìŠ¤ 3ê°œë§Œ ì¶”ì¶œ (í•µì‹¬ë§Œ)
        for item in soup.select(".news_area")[:3]:
            title = item.select_one('.news_tit').get_text()
            desc = item.select_one('.news_dsc').get_text()
            news_list.append(f"- {title} ({desc})")
            
        result = "\n".join(news_list)
        return result if result else "ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
        
    except Exception as e:
        return f"í¬ë¡¤ë§ ì—ëŸ¬: {str(e)}"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (í† í° ìµœì í™”) ---
def get_raw_sheet_text(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        response = requests.get(url)
        response.encoding = 'utf-8'
        
        f = io.StringIO(response.text)
        reader = csv.reader(f)
        all_rows = list(reader)
        
        if len(all_rows) < 2: return "ë°ì´í„° ì—†ìŒ"
        
        learned_data = []
        # ìµœì‹  50ê°œë§Œ ê°€ì ¸ì˜¤ë˜
        recent_rows = all_rows[1:][-50:]
        
        for row in recent_rows:
            clean_row = [cell.strip() for cell in row if cell.strip()]
            if len(clean_row) >= 2:
                # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì€ ê±´ ë²„ë¦¼
                if len("".join(clean_row)) > 15:
                    learned_data.append(" | ".join(clean_row))
        
        # [ì¤‘ìš”] Groq í† í° í•œë„(Request too large)ë¥¼ í”¼í•˜ê¸° ìœ„í•´
        # í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°•ì œë¡œ 2500ìë¡œ ìë¦…ë‹ˆë‹¤. (í•µì‹¬ ë°ì´í„°ë§Œ ì „ë‹¬)
        full_text = "\n".join(learned_data)
        if len(full_text) > 2500:
            full_text = full_text[-2500:] # ê°€ì¥ ìµœê·¼ ë°ì´í„° ìœ„ì£¼ë¡œ ìë¦„
            
        return full_text
    except:
        return "ë°ì´í„° ì—†ìŒ"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: Groq í˜¸ì¶œ (Geminiê¸‰ í”„ë¡¬í”„íŠ¸ íŠœë‹) ---
def generate_copy_groq(api_key, context_raw, keyword, info, user_config):
    client = Groq(api_key=api_key)
    
    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    # Geminiì˜ í’ˆì§ˆì„ ë”°ë¼ì¡ê¸° ìœ„í•œ 'ìƒì„¸ ì§€ì‹œ(System Prompt)' ê°•í™”
    # íŠ¹íˆ 'ê³µë°± ì œì™¸ ê¸€ììˆ˜'ì™€ 'ì œëª© íŒ¨í„´'ì„ ê°•ë ¥í•˜ê²Œ ì£¼ì…
    
    prompt = f"""
    Role: Senior Viral Marketing Copywriter (Korea).
    
    [GOAL]
    Write 10 high-quality marketing messages for '{keyword}'.
    
    [INPUT DATA]
    1. **News Trends:** {info} (MUST reflect these facts)
    2. **Style Reference:** {context_raw} (Copy this tone)
    
    [STRICT GUIDELINES]
    1. **Language:** Korean ONLY. (No Chinese/Vietnamese/Arabic).
    2. **Tone:** Trendy Banmal (ë°˜ë§). Use emojis properly. NO cheap slang like 'ã…‹ã…‹', 'ã… ã… '.
    3. **Title Format:** [Emoji] <{keyword}> [Keyword from News]
       - Example: ğŸ•µï¸â€â™‚ï¸ <í¬ë¼ì„ì”¬> ë²”ì¸ì€ ë°”ë¡œ ë„ˆ!
       - Length: Under 22 chars.
    4. **Body Length:** **Exactly 45~50 characters (excluding spaces).**
       - If it's too short, add more details.
       - Do NOT write "(ê´‘ê³ )" or "*ìˆ˜ì‹ ê±°ë¶€". I will add them later.
    
    [User Request]
    {custom_instruction}

    [Output Format]
    CSV format with '|' separator.
    Columns: Category | Campaign | Target | Title | Body
    
    **Output ONLY the CSV data rows.**
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6, # ì°½ì˜ì„±ì„ 0.6ìœ¼ë¡œ ë‚®ì¶°ì„œ 'í™˜ê°(í—›ì†Œë¦¬)'ì„ ì¤„ì´ê³  ì•ˆì •ì„± ë†’ì„
            max_tokens=2500,
            top_p=1,
            stream=False,
            stop=None,
        )
        return completion.choices[0].message.content, "llama-3.3-70b"

    except Exception as e:
        raise Exception(f"Groq API ì˜¤ë¥˜: {str(e)}")

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")

col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: íŒ©íŠ¸ ê¸°ë°˜, í˜¸ê¸°ì‹¬ ìê·¹")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        status_box.write("ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ìŠ¤í…”ìŠ¤ í¬ë¡¤ë§ ì¤‘...")
        search_info = get_naver_search(keyword)
        
        # ë‰´ìŠ¤ ê²°ê³¼ ë””ë²„ê¹… (ì‚¬ìš©ì í™•ì¸ìš©)
        if "ì—†ìŒ" in search_info or "ì—ëŸ¬" in search_info:
            status_box.write("âš ï¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ë¶ˆê°€ (ì¼ë°˜ ì°½ì‘ ëª¨ë“œ)")
        else:
            status_box.write("âœ… ìµœì‹  ë‰´ìŠ¤ í™•ë³´ ì™„ë£Œ!")
            with st.expander("ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ìš”ì•½ ë³´ê¸°"):
                st.text(search_info)
        
        status_box.write("ğŸ“š ì‹œíŠ¸ ë°ì´í„° ìµœì í™” í•™ìŠµ ì¤‘...")
        context_raw = get_raw_sheet_text(sheet_id_input, sheet_gid_input)
        
        status_box.write("âš¡ Groq ì—”ì§„ ê°€ë™ (Geminiê¸‰ íŠœë‹)...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            # Groq í˜¸ì¶œ
            raw_text, used_model = generate_copy_groq(FIXED_API_KEY, context_raw, keyword, search_info, config)
            
            # CSV íŒŒì‹±
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            lines = clean_csv.split('\n')
            
            data_rows = []
            for line in lines:
                if line.count('|') >= 3:
                    parts = line.split('|')
                    if 'ëŒ€ë¶„ë¥˜' in parts[0] or 'Category' in parts[0] or 'ë¶„ë¥˜' in parts[0]: continue
                    data_rows.append(parts)
            
            fixed_columns = ["ëŒ€ë¶„ë¥˜", "ìº í˜ì¸", "íƒ€ê²Ÿ", "ì œëª©", "ë‚´ìš©"]
            if data_rows:
                safe_data = []
                for row in data_rows:
                    if len(row) >= 5: safe_data.append(row[:5])
                    else: safe_data.append(row + [""] * (5 - len(row)))
                df = pd.DataFrame(safe_data, columns=fixed_columns)
            else:
                raise Exception("ìœ íš¨í•œ CSV ë°ì´í„° ìƒì„± ì‹¤íŒ¨")

            # í›„ì²˜ë¦¬: ë²•ì  ë¬¸êµ¬ & ê¸€ììˆ˜ ì œì–´
            if 'ë‚´ìš©' in df.columns:
                df['ë‚´ìš©'] = df['ë‚´ìš©'].apply(clean_and_format_final)
            
            if 'ì œëª©' in df.columns:
                df['ì œëª©'] = df['ì œëª©'].apply(lambda x: str(x).strip()[:22])
            
            status_box.update(label=f"âœ… ì™„ë£Œ! (Groq Llama 3 - Optimized)", state="complete", expanded=False)
            
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
