import streamlit as st
import pandas as pd
from groq import Groq
import requests
from bs4 import BeautifulSoup
import io
import re

# --- ğŸ”’ [API í‚¤ ì„¤ì •] ---
part1 = "gsk_lIDRWFZfRKNye7Il5egq"
part2 = "WGdyb3FY5WLFI3NtD9NB70RLy6uk4Mce"
FIXED_API_KEY = part1 + part2

FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Final Fix)")
st.markdown("êµ¬ê¸€ ì‹œíŠ¸ ì˜¤ë¥˜ ìˆ˜ì • + í•œì ì œê±° + ë§íˆ¬ ë³µì œ ê¸°ëŠ¥ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY.startswith("gsk_"):
        st.success("âœ… Groq API Key ì—°ê²°ë¨")
    else:
        st.error("API Key ì„¤ì • ì˜¤ë¥˜")
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")
    st.info("ğŸ’¡ Tip: ì‹œíŠ¸ ê³µìœ  ê¶Œí•œì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì(ë³´ê¸°)'ë¡œ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹°: í…ìŠ¤íŠ¸ ì²­ì†Œ ---
def clean_text_force_korean(text):
    # í•œì/ì¼ë³¸ì–´ ìœ ë‹ˆì½”ë“œ ë²”ìœ„ ì œê±°
    pattern = re.compile(r'[\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]+')
    cleaned_text = pattern.sub('', text)
    return cleaned_text

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: Groq í˜¸ì¶œ ---
def generate_copy_groq(api_key, context, keyword, info, user_config):
    client = Groq(api_key=api_key)
    
    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['campaign']: custom_instruction += f"- ìº í˜ì¸: {user_config['campaign']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    if not context or "ë°ì´í„° ì—†ìŒ" in context: 
        context = "ì°¸ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ SNS ë°”ì´ëŸ´ ë§ˆì¼€íŒ… í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."

    prompt = f"""
    Role: You are a Viral Marketing Copywriter expert in Korean SNS trends.
    
    [YOUR GOAL]
    Create 10 marketing messages for '{keyword}'. 
    **CRUCIAL: You must MIMIC the 'Tone and Manner' of the [Reference Data] below.** If the reference uses short slang, you utilize short slang. 
    If the reference uses specific emojis, use similar ones.
    
    [Reference Data (MIMIC THIS STYLE)]
    {context}
    
    [Trend Info]
    {info}

    [User Request]
    {custom_instruction}

    [Strict Constraints]
    1. **Language:** Korean (Hangul) ONLY. No Chinese(Hanja), No Japanese.
    2. **Format:** CSV format with '|' separator.
    3. **Columns:** ëŒ€ë¶„ë¥˜|ìº í˜ì¸|ìƒì„¸íƒ€ê²Ÿ_ìƒì„¸íƒ€ê¹ƒ_ìƒì„¸ì„¤ëª…|ì¶”ì²œ ì½˜í…ì¸ |ì œëª©|ë‚´ìš©
    4. **Length:** Title < 20 chars, Body < 40 chars.
    5. **Emoji:** Use emojis heavily (2~3 per line).
    6. **Tone:** Direct, provocative, curiosity-inducing. (e.g., "ì´ê±° ì‹¤í™”?", "ì§„ì§œ ì—­ëŒ€ê¸‰ ã„·ã„·")

    **Output ONLY the CSV data.**
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.85,
            max_tokens=2048,
            top_p=1,
            stream=False,
            stop=None,
        )
        return completion.choices[0].message.content, "llama-3.3-70b"

    except Exception as e:
        raise Exception(f"Groq API ì˜¤ë¥˜: {str(e)}")

# --- (ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ë“¤ - ê°•ë ¥ ìˆ˜ì •) ---

def get_sheet_data(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        
        # [í•µì‹¬ ìˆ˜ì •] engine='python'ì„ ì‚¬ìš©í•˜ì—¬ ë¶ˆê·œì¹™í•œ ë°ì´í„°(saw 8 fields)ë¥¼ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
        # on_bad_lines='skip': ì¹¸ ìˆ˜ê°€ ì•ˆ ë§ëŠ” í–‰ì€ ê³¼ê°íˆ ë²„ë¦¬ê³  ì½ìŒ
        df = pd.read_csv(url, encoding='utf-8', on_bad_lines='skip', engine='python')
        
        if df.empty: return None
        
        # NaN(ë¹ˆì¹¸)ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
        df = df.fillna("")
        
        # í•™ìŠµ ë°ì´í„° ìƒ˜í”Œë§ (ìµœëŒ€ 50ê°œ)
        if len(df) > 50: 
            df = df.sample(50) 
            
        return df.to_markdown(index=False)
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ë¥¼ ë‚¨ê¸°ê³  None ë°˜í™˜
        print(f"Sheet Load Error: {e}")
        return None

def get_naver_search(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=1"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        news = []
        for item in soup.select(".news_area")[:5]:
            title = item.select_one('.news_tit').get_text()
            news.append(f"- {title}")
        return "\n".join(news) if news else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    except: return "í¬ë¡¤ë§ ì°¨ë‹¨ë¨"

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")
col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: ë„íŒŒë¯¼ í„°ì§€ê²Œ")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        status_box.write("ğŸ” ë„¤ì´ë²„ ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        search_info = get_naver_search(keyword)
        
        status_box.write("ğŸ“š êµ¬ê¸€ ì‹œíŠ¸ í•™ìŠµ ì¤‘ (ì˜¤ë¥˜ ìë™ ìˆ˜ì •)...")
        sheet_data = get_sheet_data(sheet_id_input, sheet_gid_input)
        
        if sheet_data is None:
             status_box.write("âš ï¸ ì‹œíŠ¸ ë¡œë”© ì‹¤íŒ¨: ê¶Œí•œì„ í™•ì¸í•˜ê±°ë‚˜, ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        status_box.write("âš¡ Groq ì—”ì§„ ê°€ë™ (ë§íˆ¬ ë³µì œ & í•œì ì œê±°)...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            raw_text, used_model = generate_copy_groq(FIXED_API_KEY, sheet_data, keyword, search_info, config)
            
            # 1ì°¨ ì •ì œ
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            if '|' in clean_csv:
                lines = clean_csv.split('\n')
                csv_lines = [line for line in lines if '|' in line]
                clean_csv = '\n'.join(csv_lines)

            # 2ì°¨ ì •ì œ
            df = pd.read_csv(io.StringIO(clean_csv), sep='|')
            
            # 3ì°¨ ì •ì œ (ë²•ì  ë¬¸êµ¬ + í•œì í•„í„°)
            if any('ë‚´ìš©' in c for c in df.columns):
                content_col = [c for c in df.columns if 'ë‚´ìš©' in c][0] 
                
                def final_clean(text):
                    text = clean_text_force_korean(str(text))
                    text = text.strip()
                    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"

                df[content_col] = df[content_col].apply(final_clean)
            
            status_box.update(label=f"âœ… ì™„ë£Œ! ({used_model})", state="complete", expanded=False)
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
