import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import io
import json

# --- ğŸ”’ [ì‚¬ìš©ì ê³ ì • ì„¤ì •] ---
FIXED_API_KEY = 'AIzaSyAuZqhGnynPLvbpjjbJC7CDR24LZtzVQO4'.strip() 
FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="ğŸ§â€â™‚ï¸", layout="wide")
st.title("ğŸ§â€â™‚ï¸ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Safe Mode)")
st.markdown("ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ **ë‹¤ë¥¸ ë²„ì „ì˜ 1.5 ëª¨ë¸**ë¡œ ì¦‰ì‹œ ì „í™˜í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY:
        st.success("ğŸ”‘ API Key ì ìš©ë¨")
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID", value="0")

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ë  ë•Œê¹Œì§€ ë‘ë“œë¦¬ê¸° ---

def call_gemini_brute_force(api_key, prompt):
    """
    í•˜ë‚˜ì˜ ëª¨ë¸ ì´ë¦„ì— ì˜ì¡´í•˜ì§€ ì•Šê³ , 
    ì„±ê³µí•  ë•Œê¹Œì§€ ì¤€ë¹„ëœ ì•ˆì „í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•©ë‹ˆë‹¤.
    (2.5 ë²„ì „ ì œì™¸, 1.5 ìœ„ì£¼ êµ¬ì„±)
    """
    # ì‹œë„í•  ëª¨ë¸ ëª©ë¡ (ìˆœì„œëŒ€ë¡œ ì‹œë„)
    safe_models = [
        "gemini-1.5-flash",          # 1ìˆœìœ„: ê¸°ë³¸ ë³„ëª…
        "gemini-1.5-flash-001",      # 2ìˆœìœ„: êµ¬ë²„ì „ ëª…ì‹œ
        "gemini-1.5-flash-002",      # 3ìˆœìœ„: ì‹ ë²„ì „ ëª…ì‹œ
        "gemini-1.5-flash-latest",   # 4ìˆœìœ„: ìµœì‹  ë³„ëª…
        "gemini-1.5-pro",            # 5ìˆœìœ„: í”Œë˜ì‹œ ì•ˆë˜ë©´ í”„ë¡œ
        "gemini-pro"                 # 6ìˆœìœ„: êµ¬í˜• í”„ë¡œ (ìµœí›„ì˜ ìˆ˜ë‹¨)
    ]
    
    logs = [] # ì‹¤íŒ¨ ë¡œê·¸ ê¸°ë¡ìš©

    print("ğŸš€ ìƒì„± ì‹œì‘...")

    for model_name in safe_models:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
        headers = {'Content-Type': 'application/json'}
        data = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {"temperature": 0.7}
        }
        
        try:
            # ìš”ì²­ ì „ì†¡
            response = requests.post(url, headers=headers, json=data, timeout=20)
            
            # 200 OKê°€ ì•„ë‹ˆë©´ ë‹¤ìŒìœ¼ë¡œ
            if response.status_code != 200:
                fail_msg = f"âš ï¸ [{model_name}] ì‹¤íŒ¨ (Status {response.status_code})"
                print(fail_msg)
                logs.append(fail_msg)
                continue 
            
            # ì‘ë‹µ íŒŒì‹±
            result = response.json()
            if 'candidates' in result and result['candidates']:
                content = result['candidates'][0].get('content')
                if content and 'parts' in content:
                    # â˜… ì„±ê³µ ì‹œ ë°”ë¡œ ë¦¬í„´ (ë£¨í”„ ì¢…ë£Œ) â˜…
                    return content['parts'][0]['text'], model_name
            
            # ì‘ë‹µì€ ì™”ëŠ”ë° ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°
            logs.append(f"âš ï¸ [{model_name}] ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
            continue

        except Exception as e:
            logs.append(f"âŒ [{model_name}] ì—°ê²° ì—ëŸ¬: {e}")
            continue

    # ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš°
    error_summary = "\n".join(logs)
    raise Exception(f"ëª¨ë“  ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨. (ìƒì„¸ ë¡œê·¸ ì•„ë˜)\n{error_summary}")


# --- (ë‚˜ë¨¸ì§€ í•¨ìˆ˜ ë™ì¼) ---
def get_sheet_data(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        df = pd.read_csv(url, encoding='utf-8', on_bad_lines='skip')
        if df.empty: return None
        if len(df) > 30: df = df.tail(30)
        return df.to_markdown(index=False)
    except: return None

def get_naver_search(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=1"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        news = [f"[{item.select_one('.news_tit').get_text()}]: {item.select_one('.news_dsc').get_text()}" for item in soup.select(".news_area")[:5]]
        return "\n".join(news) if news else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    except: return "í¬ë¡¤ë§ ì°¨ë‹¨ë¨"

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")
col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 30ëŒ€ ì§ì¥ì¸")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: ì´ëª¨ì§€ ë§ì´")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        # 1. ì •ë³´ ìˆ˜ì§‘
        status_box.write("ğŸ” ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        search_info = get_naver_search(keyword)
        sheet_data = get_sheet_data(sheet_id_input, sheet_gid_input)
        
        # 2. ìƒì„± (ë¬´í•œ ì¬ì‹œë„)
        status_box.write("ğŸ¤– 1.5 ëª¨ë¸ ì—°ê²° ì‹œë„ ì¤‘ (ìˆœì°¨ ì ‘ì†)...")
        try:
            prompt = f"Role: Copywriter.\nRef: {sheet_data}\nNews: {search_info}\nRequest: {note}\nCreate 5 copies for {keyword}. Output Format: CSV with '|' separator."
            
            # ì—¬ê¸°ì„œ 6ê°œ ëª¨ë¸ì„ ìˆœì„œëŒ€ë¡œ ë‹¤ ì°”ëŸ¬ë´…ë‹ˆë‹¤
            raw_text, used_model = call_gemini_brute_force(FIXED_API_KEY, prompt)
            
            # í›„ì²˜ë¦¬
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            df = pd.read_csv(io.StringIO(clean_csv), sep='|')
            
            # ë²•ì  ë¬¸êµ¬ ì¶”ê°€
            content_col = [c for c in df.columns if 'ë‚´ìš©' in c][0] 
            df[content_col] = df[content_col].apply(lambda x: f"(ê´‘ê³ ) {str(x).strip()}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½")
            
            status_box.update(label=f"âœ… ì„±ê³µ! (ì—°ê²°ëœ ëª¨ë¸: {used_model})", state="complete", expanded=False)
            st.subheader("ğŸ“Š ê²°ê³¼")
            st.dataframe(df)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨", state="error")
            st.error(f"ìµœì¢… ì—ëŸ¬ ë‚´ìš©:\n{e}")
