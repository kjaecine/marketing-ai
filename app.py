import streamlit as st
import pandas as pd
import google.generativeai as genai
import requests
import io
from duckduckgo_search import DDGS

# --- ğŸ¨ í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (High RPD Only)")
st.markdown("ğŸš€ **ì¼ì¼ 1,500íšŒ+ ìš”ì²­ ê°€ëŠ¥í•œ ê³ ì† ëª¨ë¸(Flash/Lite)** ì „ìš© ë²„ì „")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def get_news_search_ddg(keyword):
    """DuckDuckGo ë‰´ìŠ¤ ê²€ìƒ‰ (ë„¤ì´ë²„ ì°¨ë‹¨ ìš°íšŒ)"""
    try:
        results = DDGS().text(f"{keyword} ë‰´ìŠ¤", region='kr-kr', max_results=5)
        if not results: return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
        
        news_summary = []
        for r in results:
            news_summary.append(f"[{r.get('title','')}]: {r.get('body','')}")
        return "\n\n".join(news_summary)
    except Exception as e:
        return f"ê²€ìƒ‰ ì—ëŸ¬: {str(e)}"

def get_sheet_data(sheet_id, gid):
    """êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„°"""
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        df = pd.read_csv(url, encoding='utf-8', on_bad_lines='skip')
        if df.empty: return None
        if len(df) > 50: df = df.tail(50)
        return df.to_markdown(index=False)
    except:
        return None

def generate_plan_high_rpd(api_key, context, keyword, info, user_config):
    genai.configure(api_key=api_key)
    
    # [í•µì‹¬] RPDê°€ ë†’ì€(500íšŒ ì´ìƒ) ëª¨ë¸ë§Œ ë¦¬ìŠ¤íŠ¸ì—…
    # 1ìˆœìœ„: ì‚¬ìš©ìë‹˜ì´ ì›í•˜ì‹  2.0 Flash Lite
    # 2ìˆœìœ„: 1.5 Flash (ê°€ì¥ ëŒ€ì¤‘ì ì¸ ëŒ€ìš©ëŸ‰)
    # 3ìˆœìœ„: 1.5 Flash 8b (ì´ˆê³ ì†/ëŒ€ìš©ëŸ‰)
    high_rpd_models = [
        'gemini-2.0-flash-lite-preview-02-05',
        'gemini-1.5-flash',
        'gemini-1.5-flash-8b'
    ]
    
    selected_model = None
    response_text = None
    last_error = None

    # ê³ ì† ëª¨ë¸ ìˆœì°¨ ì‹œë„
    for model_name in high_rpd_models:
        try:
            model = genai.GenerativeModel(model_name)
            
            custom_instruction = ""
            if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
            if user_config['campaign']: custom_instruction += f"- ìº í˜ì¸: {user_config['campaign']}\n"
            if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

            if not context: context = "ë°ì´í„° ì—†ìŒ."

            prompt = f"""
            Role: Senior Viral Marketing Copywriter (Korea).
            
            [Mission]
            1. **STYLE CLONING:** Analyze the [Reference] data. Copy the tone, manner, and emoji usage exactly.
            2. Create 10 marketing messages for '{keyword}'.
            3. **STRICT LIMITS (CRITICAL):**
            - **Title:** UNDER 20 Korean characters.
            - **Body:** **Exactly 40~50 characters (Excluding spaces).** - Do NOT write '(ê´‘ê³ )' or '*ìˆ˜ì‹ ê±°ë¶€'. I will add them via code.
            4. Apply [User Request].

            [Reference Data]
            {context}

            [News/Trends Info]
            {info}

            [User Request]
            {custom_instruction}

            [Output Format]
            ëŒ€ë¶„ë¥˜|ìº í˜ì¸|íƒ€ê²Ÿ|ì½˜í…ì¸ |ì œëª©|ë‚´ìš©
            (CSV format with '|' separator. NO markdown.)
            """
            
            # ì•ˆì „ ì„¤ì • í•´ì œ
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
            
            response = model.generate_content(prompt, safety_settings=safety_settings)
            
            # ì„±ê³µí•˜ë©´ ë°”ë¡œ ë°˜í™˜
            if response.text:
                selected_model = model_name
                response_text = response.text
                break
                
        except Exception as e:
            last_error = e
            continue # ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ ê³ ì† ëª¨ë¸ ì‹œë„

    if not response_text:
        raise Exception(f"ëª¨ë“  ê³ ì† ëª¨ë¸(Flash/Lite) í˜¸ì¶œ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì—ëŸ¬: {last_error}")

    return response_text, selected_model

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    user_api_key = st.text_input("Google API Key", type="password")
    
    st.info("ğŸš€ **High RPD Mode Active**\nì‚¬ìš©ìë‹˜ì˜ ìš”ì²­ëŒ€ë¡œ RPD(ì¼ì¼ì‚¬ìš©ëŸ‰)ê°€ ë†’ì€ ëª¨ë¸ë§Œ ê³¨ë¼ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    st.divider()
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value='1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw')
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ–¥ï¸ ë©”ì¸ í™”ë©´ ---

col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input(":loudspeaker: í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    campaign = st.text_input(":bookmark: ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")

col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input(":dart: íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input(":memo: ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: íŒ©íŠ¸ ê¸°ë°˜, í˜¸ê¸°ì‹¬ ìê·¹")

if st.button(":rocket: ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not user_api_key:
        st.error("ğŸš¨ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        # 1. ê²€ìƒ‰
        status_box.write(":mag: ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ (DuckDuckGo ìš°íšŒ)...")
        search_info = get_news_search_ddg(keyword)
        
        if "ì—ëŸ¬" in search_info or "ì—†ìŒ" in search_info:
             status_box.write(f"âš ï¸ ê²€ìƒ‰ ì´ìŠˆ: {search_info}")
        else:
             status_box.write("âœ… ìµœì‹  ì •ë³´ í™•ë³´ ì™„ë£Œ!")
        
        # 2. ì‹œíŠ¸
        status_box.write(":books: êµ¬ê¸€ ì‹œíŠ¸ í•™ìŠµ ì¤‘...")
        sheet_data = get_sheet_data(sheet_id_input, sheet_gid_input)
        
        # 3. ìƒì„±
        status_box.write(f":robot_face: ê³ ì† ëª¨ë¸(Flash/Lite) ì—”ì§„ ê°€ë™...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            # í•¨ìˆ˜ í˜¸ì¶œ ë³€ê²½: ê³ ì† ëª¨ë¸ë§Œ ì‚¬ìš©
            raw_text, used_model = generate_plan_high_rpd(user_api_key, sheet_data, keyword, search_info, config)
            
            # íŒŒì‹± & í›„ì²˜ë¦¬
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            df = pd.read_csv(io.StringIO(clean_csv), sep='|')
            
            content_cols = [c for c in df.columns if 'ë‚´ìš©' in c]
            if content_cols:
                content_col = content_cols[0]
                def final_formatter(text):
                    text = str(text).replace("(ê´‘ê³ )", "").replace("*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½", "").strip()
                    if len(text) > 60: text = text[:58] + ".."
                    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"
                df[content_col] = df[content_col].apply(final_formatter)
            
            status_box.update(label=f":white_check_mark: ì™„ë£Œ! (ì‚¬ìš© ëª¨ë¸: {used_model})", state="complete", expanded=False)
            
            st.subheader(":bar_chart: ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(":inbox_tray: ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label=":x: ì˜¤ë¥˜", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
            st.warning("íŒ: 'Limit 0' ì—ëŸ¬ê°€ ê³„ì†ëœë‹¤ë©´, í•´ë‹¹ êµ¬ê¸€ ê³„ì •ì— ê²°ì œ ì •ë³´ê°€ ì—†ê±°ë‚˜ ë¬´ë£Œ í‹°ì–´ í• ë‹¹ëŸ‰ì´ ì†Œì§„ëœ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
