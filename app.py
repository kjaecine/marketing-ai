import streamlit as st
import pandas as pd
from groq import Groq
import requests
from bs4 import BeautifulSoup
import io
import re
import csv # CSV ì •ë°€ íŒŒì‹±ì„ ìœ„í•´ ì¶”ê°€

# --- ğŸ”’ [API í‚¤ ì„¤ì •] ---
part1 = "gsk_lIDRWFZfRKNye7Il5egq"
part2 = "WGdyb3FY5WLFI3NtD9NB70RLy6uk4Mce"
FIXED_API_KEY = part1 + part2
FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Real Sheet Learning)")
st.markdown("íŠ¹ì • ì˜ˆì‹œ ì—†ì´ **ì‚¬ìš©ìì˜ êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ** í•™ìŠµí•©ë‹ˆë‹¤.")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY.startswith("gsk_"):
        st.success("âœ… Groq API Key ì—°ê²°ë¨")
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹°: í…ìŠ¤íŠ¸ ì²­ì†Œ ---
def clean_text_strict(text):
    # ì™¸êµ­ì–´ ì œê±°
    pattern = re.compile(r'[\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF\u0600-\u06FF]+')
    text = pattern.sub('', str(text))
    return re.sub(r'\s+', ' ', text).strip()

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ì‹œíŠ¸ ë°ì´í„° 'ë‚ ê²ƒ'ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° ---
def get_raw_sheet_text(sheet_id, gid):
    """
    Pandasë¡œ í‘œë¥¼ ë§Œë“¤ë ¤ë‹¤ê°€ ì—ëŸ¬ê°€ ë‚˜ë‹ˆ, 
    ê·¸ëƒ¥ í…ìŠ¤íŠ¸ ë©ì–´ë¦¬ë¡œ ê°€ì ¸ì™€ì„œ AIì—ê²Œ ë˜ì ¸ì¤ë‹ˆë‹¤.
    """
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        response = requests.get(url)
        response.encoding = 'utf-8'
        
        # 1. í…ìŠ¤íŠ¸ë¡œ ë°›ì•„ì˜´
        raw_text = response.text
        
        # 2. CSV ë¦¬ë”ë¡œ í•œ ì¤„ì”© íŒŒì‹± (ì—ëŸ¬ ì—†ì´ ì½ê¸° ìœ„í•´)
        # ì‰¼í‘œê°€ í¬í•¨ëœ ë¬¸ì¥ë„ csv ëª¨ë“ˆì€ ì˜ ì²˜ë¦¬í•¨
        f = io.StringIO(raw_text)
        reader = csv.reader(f)
        
        learned_data = []
        
        # 3. ë°ì´í„° ì¶”ì¶œ (í—¤ë” ì œì™¸í•˜ê³  ìµœê·¼ 50ê°œ í–‰ë§Œ)
        all_rows = list(reader)
        if len(all_rows) < 2: return "ë°ì´í„° ì—†ìŒ"
        
        # ìµœì‹  íŠ¸ë Œë“œ ë°˜ì˜ì„ ìœ„í•´ ë’¤ì—ì„œë¶€í„° 50ê°œ
        target_rows = all_rows[1:][-50:] 
        
        for row in target_rows:
            # ë¹ˆ ì¹¸ ì œê±°í•˜ê³  í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ í•©ì¹¨
            # ì˜ˆ: ["ì—”í„°", "í™˜ìŠ¹ì—°ì• ", "ì œëª©..", "ë‚´ìš©.."] -> "ì—”í„° | í™˜ìŠ¹ì—°ì•  | ì œëª©.. | ë‚´ìš©.."
            clean_row = [cell.strip() for cell in row if cell.strip()]
            if len(clean_row) >= 2: # ìµœì†Œí•œ ë°ì´í„°ê°€ 2ì¹¸ ì´ìƒì€ ìˆì–´ì•¼ í•™ìŠµ
                row_str = " | ".join(clean_row)
                learned_data.append(row_str)
        
        # AIì—ê²Œ ì¤„ ìµœì¢… í…ìŠ¤íŠ¸
        return "\n".join(learned_data)

    except Exception as e:
        return f"Error: {str(e)}"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: Groq í˜¸ì¶œ ---
def generate_copy_groq(api_key, context_raw, keyword, info, user_config):
    client = Groq(api_key=api_key)
    
    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    prompt = f"""
    Role: You are a Viral Marketing Copywriter expert in Korean SNS trends.
    
    [YOUR MISSION]
    Create 10 marketing messages for '{keyword}'.
    
    [CRITICAL: STYLE CLONING]
    Below is the **Raw Data** from the user's past performance.
    Analyze the **structure, length, tone, and emoji usage** from this data and generate NEW copies that look exactly like them.
    
    [User's Past Data (Raw Text)]
    {context_raw}
    
    [Trend Info]
    {info}

    [User Request]
    {custom_instruction}

    [Constraints]
    1. **Language:** Korean (Hangul) ONLY. No Foreign languages.
    2. **Format:** CSV with '|' separator.
    3. **Columns:** ëŒ€ë¶„ë¥˜|ìº í˜ì¸|íƒ€ê²Ÿ|ì½˜í…ì¸ |ì œëª©|ë‚´ìš©
    4. **Volume:**
       - **Title:** 20~30 characters.
       - **Body:** 50~80 characters. (Write fully and emotionally. Do not cut it short.)
    5. **Tone:** Use the same tone found in [User's Past Data].

    **Output ONLY the CSV data.**
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.75, 
            max_tokens=2500,
            top_p=1,
            stream=False,
            stop=None,
        )
        return completion.choices[0].message.content, "llama-3.3-70b"

    except Exception as e:
        raise Exception(f"Groq API ì˜¤ë¥˜: {str(e)}")

# --- (ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜) ---
def get_naver_search(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=1"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        news = []
        for item in soup.select(".news_area")[:3]:
            title = item.select_one('.news_tit').get_text()
            news.append(f"- {title}")
        return "\n".join(news) if news else ""
    except: return ""

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")
col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: ìê·¹ì ìœ¼ë¡œ")

# --- ë°ì´í„° í™•ì¸ìš© ---
with st.expander("ğŸ“Š í•™ìŠµ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Raw Text)"):
    if st.button("ë°ì´í„° ë¡œë“œ í™•ì¸"):
        raw_text = get_raw_sheet_text(sheet_id_input, sheet_gid_input)
        if len(raw_text) > 50:
            st.success("âœ… ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
            st.text_area("AIê°€ í•™ìŠµí•  ì‹¤ì œ ë°ì´í„°", raw_text, height=300)
        else:
            st.error("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ í˜¹ì€ ë‚´ìš© ë¶€ì¡±.")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        status_box.write("ğŸ” íŠ¸ë Œë“œ & ì‹œíŠ¸ í•™ìŠµ ì¤‘...")
        search_info = get_naver_search(keyword)
        
        # ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Raw Text ë°©ì‹)
        context_raw = get_raw_sheet_text(sheet_id_input, sheet_gid_input)
        
        if len(context_raw) < 50:
             status_box.write("âš ï¸ ì‹œíŠ¸ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        
        status_box.write("âš¡ Groq ì—”ì§„ ê°€ë™ (ì‚¬ìš©ì ìŠ¤íƒ€ì¼ ë³µì œ)...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            raw_text, used_model = generate_copy_groq(FIXED_API_KEY, context_raw, keyword, search_info, config)
            
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            if '|' in clean_csv:
                lines = clean_csv.split('\n')
                csv_lines = [line for line in lines if line.count('|') >= 4] 
                clean_csv = '\n'.join(csv_lines)

            df = pd.read_csv(io.StringIO(clean_csv), sep='|')
            
            # í›„ì²˜ë¦¬
            if any('ë‚´ìš©' in c for c in df.columns):
                content_col = [c for c in df.columns if 'ë‚´ìš©' in c][0] 
                
                def final_clean(text):
                    text = clean_text_strict(str(text))
                    # 50ì ë¯¸ë§Œì´ë©´ AIê°€ ì„±ì˜ì—†ê²Œ ì“´ ê±°ë‹ˆ ë’¤ì— ë¬¸êµ¬ ì¶”ê°€
                    if len(text) < 40: 
                        text += " ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•˜ê³  ë„íŒŒë¯¼ ì¶©ì „í•˜ì„¸ìš”! âš¡"
                    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"

                df[content_col] = df[content_col].apply(final_clean)
            
            # ì œëª© ê¸¸ì´ ì •ë¦¬
            if any('ì œëª©' in c for c in df.columns):
                title_col = [c for c in df.columns if 'ì œëª©' in c][0]
                df[title_col] = df[title_col].apply(lambda x: clean_text_strict(str(x))[:30]) 

            status_box.update(label=f"âœ… ì™„ë£Œ!", state="complete", expanded=False)
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
