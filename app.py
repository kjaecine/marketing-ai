import streamlit as st
import pandas as pd
import google.generativeai as genai
import requests
import io
from duckduckgo_search import DDGS # ê°•ë ¥í•œ ìš°íšŒ ê²€ìƒ‰ ë„êµ¬

# --- ğŸ¨ í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="ğŸ§â€â™‚ï¸", layout="wide")
st.title("ğŸ§â€â™‚ï¸ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Secure & Stable)")
st.markdown("âš ï¸ **API í‚¤ ë³´ì•ˆ ëª¨ë“œ** + **ê²€ìƒ‰ ì—”ì§„ ìš°íšŒ(DuckDuckGo)** ì ìš©ë¨")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” (API í‚¤ ì…ë ¥) ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # [ë³´ì•ˆ] ì½”ë“œê°€ ì•„ë‹ˆë¼ ì—¬ê¸°ì„œ ì§ì ‘ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.
    user_api_key = st.text_input("AIzaSyA1HhzAK2y_TCKjb1tG3M7GHnmC5uKh4WM", type="password", help="ìƒˆë¡œ ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì—¬ê¸°ì— ë„£ìœ¼ì„¸ìš”.")
    
    if not user_api_key:
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        st.success("âœ… í‚¤ ì…ë ¥ë¨")

    st.divider()
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value='1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw')
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜ë“¤ ---

def get_news_search_ddg(keyword):
    """
    ë„¤ì´ë²„ ì°¨ë‹¨ì„ í”¼í•˜ê¸° ìœ„í•´ DuckDuckGo ì—”ì§„ì„ í†µí•´ 
    'í‚¤ì›Œë“œ + ë‰´ìŠ¤'ë¥¼ ê²€ìƒ‰í•˜ì—¬ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (ì°¨ë‹¨ í™•ë¥  0%)
    """
    try:
        results = DDGS().text(f"{keyword} ìµœì‹  ë‰´ìŠ¤", max_results=5)
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
        
        news_summary = []
        for r in results:
            title = r.get('title', '')
            body = r.get('body', '')
            news_summary.append(f"[{title}]: {body}")
            
        return "\n\n".join(news_summary)
    except Exception as e:
        return f"ê²€ìƒ‰ ì—ëŸ¬: {str(e)}"

def get_sheet_data(sheet_id, gid):
    """êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        df = pd.read_csv(url, encoding='utf-8', on_bad_lines='skip')
        if df.empty: return None
        if len(df) > 50: df = df.tail(50)
        return df.to_markdown(index=False)
    except:
        return None

def generate_plan(api_key, context, keyword, info, user_config):
    """Gemini í˜¸ì¶œ"""
    genai.configure(api_key=api_key)
    
    # ìµœì‹  ëª¨ë¸ ìš°ì„  ì‹œë„, ì‹¤íŒ¨ ì‹œ ì•ˆì •ì ì¸ Pro ëª¨ë¸ ì‚¬ìš©
    model_name = 'gemini-2.0-flash-lite-preview-02-05'
    try:
        model = genai.GenerativeModel(model_name)
    except:
        model_name = 'gemini-1.5-flash' # ë°±ì—…
        model = genai.GenerativeModel(model_name)

    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['campaign']: custom_instruction += f"- ìº í˜ì¸: {user_config['campaign']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    if not context: context = "ë°ì´í„° ì—†ìŒ."

    prompt = f"""
    Role: Senior Viral Marketing Copywriter (Korea).
    
    [Mission]
    1. **STYLE CLONING:** Analyze the [Reference] data. Copy the tone, manner, and emoji usage exactly.
    2. Create 10 marketing messages for '{keyword}'.
    3. **STRICT LIMITS (CRITICAL):**
       - **Title:** UNDER 20 Korean characters.
       - **Body:** **Exactly 40~50 characters (Excluding spaces).** - Do NOT write '(ê´‘ê³ )' or '*ìˆ˜ì‹ ê±°ë¶€'.
    4. Apply [User Request].

    [Reference Data]
    {context}

    [News/Trends Info]
    {info}

    [User Request]
    {custom_instruction}

    [Output Format]
    ëŒ€ë¶„ë¥˜|ìº í˜ì¸|íƒ€ê²Ÿ|ì½˜í…ì¸ |ì œëª©|ë‚´ìš©
    (CSV format with '|' separator. NO markdown.)
    """
    
    response = model.generate_content(prompt)
    return response.text, model_name

# --- ğŸ–¥ï¸ ë©”ì¸ í™”ë©´ UI ---

col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input(":loudspeaker: í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í™˜ìŠ¹ì—°ì• 4")
with col2:
    campaign = st.text_input(":bookmark: ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")

col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input(":dart: íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input(":memo: ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: íŒ©íŠ¸ ê¸°ë°˜, í˜¸ê¸°ì‹¬ ìê·¹")

if st.button(":rocket: ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not user_api_key:
        st.error("ğŸš¨ ì‚¬ì´ë“œë°”ì— ìƒˆ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”! (ê¸°ì¡´ í‚¤ëŠ” ìœ ì¶œë¡œ ì¸í•´ ì°¨ë‹¨ë¨)")
    elif not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        # 1. ê²€ìƒ‰
        status_box.write(":mag: ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ (ìš°íšŒ ëª¨ë“œ)...")
        search_info = get_news_search_ddg(keyword)
        
        if "ì—ëŸ¬" in search_info or "ì—†ìŒ" in search_info:
             status_box.write(f"âš ï¸ ê²€ìƒ‰ ì´ìŠˆ: {search_info}")
        else:
             status_box.write("âœ… ìµœì‹  ì •ë³´ í™•ë³´ ì™„ë£Œ!")
        
        # 2. ì‹œíŠ¸
        status_box.write(":books: êµ¬ê¸€ ì‹œíŠ¸ í•™ìŠµ ì¤‘...")
        sheet_data = get_sheet_data(sheet_id_input, sheet_gid_input)
        
        # 3. ìƒì„±
        status_box.write(f":robot_face: Gemini ì—”ì§„ ê°€ë™...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            raw_text, used_model = generate_plan(user_api_key, sheet_data, keyword, search_info, config)
            
            # íŒŒì‹±
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            df = pd.read_csv(io.StringIO(clean_csv), sep='|')
            
            # í›„ì²˜ë¦¬
            content_cols = [c for c in df.columns if 'ë‚´ìš©' in c]
            if content_cols:
                content_col = content_cols[0]
                def final_formatter(text):
                    text = str(text).replace("(ê´‘ê³ )", "").replace("*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½", "").strip()
                    if len(text) > 60: text = text[:58] + ".."
                    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"
                df[content_col] = df[content_col].apply(final_formatter)
            
            status_box.update(label=f":white_check_mark: ì™„ë£Œ! (ëª¨ë¸: {used_model})", state="complete", expanded=False)
            
            st.subheader(":bar_chart: ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(":inbox_tray: ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label=":x: ì˜¤ë¥˜", state="error")
            if "403" in str(e):
                st.error("ğŸš¨ API í‚¤ ì˜¤ë¥˜: ì…ë ¥í•˜ì‹  í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
