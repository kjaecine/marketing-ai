import streamlit as st
import pandas as pd
from groq import Groq
import requests
from bs4 import BeautifulSoup
import io
import re
import csv
import random

# --- ğŸ”’ [API í‚¤ ì„¤ì •] ---
part1 = "gsk_lIDRWFZfRKNye7Il5egq"
part2 = "WGdyb3FY5WLFI3NtD9NB70RLy6uk4Mce"
FIXED_API_KEY = part1 + part2
FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Foreign Filter & Fact Check)")
st.markdown("ì™¸êµ­ì–´(ë² íŠ¸ë‚¨ì–´/í•œì) ì™„ì „ ì°¨ë‹¨ + ë„¤ì´ë²„ ë‰´ìŠ¤ ë°˜ì˜ ì—¬ë¶€ í™•ì¸ ê¸°ëŠ¥")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY.startswith("gsk_"):
        st.success("âœ… Groq API Key ì—°ê²°ë¨")
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹°: í…ìŠ¤íŠ¸ ì •ì œ (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë°©ì‹) ---
def clean_and_format_legal_text(text):
    if not isinstance(text, str): return str(text)
    
    # 1. ì¤‘ë³µ ë²•ì  ë¬¸êµ¬ ì œê±°
    text = text.replace("(ê´‘ê³ )", "").replace("*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½", "")
    text = text.replace('"', '').replace("'", "")
    
    # 2. [ê°•ë ¥ ìˆ˜ì •] í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
    # í•œê¸€(ê°€-í£, ìëª¨), ì˜ì–´(a-zA-Z), ìˆ«ì(0-9), ê¸°ë³¸ë¬¸ì¥ë¶€í˜¸, ì´ëª¨ì§€ ì™¸ì—ëŠ” ë‹¤ ì‚­ì œ
    # ì´ë ‡ê²Œ í•˜ë©´ ë² íŠ¸ë‚¨ì–´, í•œì, ì•„ëì–´ ë“±ì´ ë“¤ì–´ì˜¬ í‹ˆì´ ì—†ìŒ
    # ì´ëª¨ì§€ ë²”ìœ„ëŠ” ë„“ì–´ì„œ ì •ê·œì‹ìœ¼ë¡œ ì‚´ë¦¬ê¸° ê¹Œë‹¤ë¡œìš°ë¯€ë¡œ, 
    # ë°˜ëŒ€ë¡œ 'ë‚¨ê¸¸ ë¬¸ì'ë¥¼ ì •ì˜í•˜ê³  ë‚˜ë¨¸ì§ˆ ì§€ìš°ëŠ” ë°©ì‹ ëŒ€ì‹ ,
    # í™•ì‹¤í•œ 'ì œê±° ëŒ€ìƒ'ì„ ê´‘ë²”ìœ„í•˜ê²Œ ì¡ëŠ” ê²ƒì´ ì•ˆì „í•  ìˆ˜ ìˆìœ¼ë‚˜, 
    # ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ 'ì´ìƒí•œ ë¬¸ì'ê°€ ì ˆëŒ€ ì•ˆ ë‚˜ì˜¤ê²Œ í•˜ë ¤ë©´ ì•„ë˜ ë°©ì‹ ì‚¬ìš©:
    
    # (í•œê¸€ | ì˜ì–´ | ìˆ«ì | ê³µë°± | ë¬¸ì¥ë¶€í˜¸)ë§Œ ë‚¨ê¸°ê³  ë‹¤ ì§€ì›€. 
    # ë‹¨, ì´ëª¨ì§€ëŠ” ì‚´ë ¤ì•¼ í•˜ë¯€ë¡œ ì´ëª¨ì§€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„ë¥¼ ì œì™¸í•˜ê³  ì‚­ì œí•˜ëŠ” ê±´ ë³µì¡í•¨.
    # ë”°ë¼ì„œ, ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•: "í•œì, ë¼í‹´ í™•ì¥(ë² íŠ¸ë‚¨ì–´ ë“±), ê¸°íƒ€ íŠ¹ìˆ˜ë¬¸ì"ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚­ì œ.
    
    # CJK(í•œì), Latin Extended(ë² íŠ¸ë‚¨ì–´ ë“±), Arabic, Cyrillic ë“± ì œê±°
    dirty_pattern = re.compile(r'[\u4E00-\u9FFF\u00C0-\u024F\u1E00-\u1EFF\u0600-\u06FF\u0400-\u04FF]+')
    text = dirty_pattern.sub('', text)
    
    # 3. ê³µë°± ì •ë¦¬
    text = text.strip()
    
    # 4. ë²•ì  ë¬¸êµ¬ ë¶€ì°©
    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ---
def get_raw_sheet_text(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        response = requests.get(url)
        response.encoding = 'utf-8'
        
        f = io.StringIO(response.text)
        reader = csv.reader(f)
        all_rows = list(reader)
        
        if len(all_rows) < 2: return "ë°ì´í„° ì—†ìŒ"
        
        learned_data = []
        recent_rows = all_rows[1:][-300:] # ìµœì‹  300ê°œ
        
        # ëœë¤ ìƒ˜í”Œë§ 60ê°œ (í† í° ì ˆì•½)
        if len(recent_rows) > 60:
            target_rows = random.sample(recent_rows, 60)
        else:
            target_rows = recent_rows
        
        for row in target_rows:
            clean_row = [cell.strip() for cell in row if cell.strip()]
            if len(clean_row) >= 2:
                if len("".join(clean_row)) > 20:
                    row_str = " | ".join(clean_row)
                    learned_data.append(row_str)
        
        return "\n".join(learned_data)
    except Exception as e:
        return f"Error: {str(e)}"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ì •ë³´ ìˆ˜ì§‘ (ê°•í™”ë¨) ---
def get_naver_search(keyword):
    try:
        # ê²€ìƒ‰ì–´ì— 'ìµœì‹ ' ë“±ì„ ë¶™ì—¬ì„œ ì •í™•ë„ ë†’ì„ (ì˜ˆ: ë‚˜ëŠ”solo -> ë‚˜ëŠ”solo ìµœì‹ )
        search_query = f"{keyword}"
        url = f"https://search.naver.com/search.naver?where=news&query={search_query}&sm=tab_opt&sort=1" # sort=1 ìµœì‹ ìˆœ
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        news_list = []
        # ë‰´ìŠ¤ 5ê°œ ê¸ì–´ì˜´ (ì œëª© + ìš”ì•½ë¬¸)
        for item in soup.select(".news_area")[:5]:
            title = item.select_one('.news_tit').get_text()
            desc = item.select_one('.news_dsc').get_text()
            news_list.append(f"Title: {title}\nSummary: {desc}")
            
        result = "\n---\n".join(news_list)
        return result if result else "ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (AIê°€ ì¼ë°˜ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤)"
    except Exception as e:
        return f"í¬ë¡¤ë§ ì—ëŸ¬: {str(e)}"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: Groq í˜¸ì¶œ ---
def generate_copy_groq(api_key, context_raw, keyword, info, user_config):
    client = Groq(api_key=api_key)
    
    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    prompt = f"""
    Role: Professional Viral Marketing Copywriter (Korea).
    
    [YOUR MISSION]
    Create 10 marketing messages for '{keyword}'.
    
    [SOURCE OF TRUTH - NEWS DATA]
    **You MUST use the information below.** If this data contains specific season numbers (e.g., 23ê¸°, 24ê¸°) or names (e.g., ì˜ìˆ™, ê´‘ìˆ˜), USE THEM.
    **Do NOT invent season numbers (like 28ê¸°) if they are not in the news.**
    
    [News Data]
    {info}
    
    [STRICT TITLE FORMAT]
    **[Emoji] <{keyword}> [Trend/News Hook]**
    - Example: ğŸ’˜ <ë‚˜ëŠ”ì†”ë¡œ> 23ê¸° ê²°í˜¼ ì»¤í”Œ íƒ„ìƒ?
    - Keep under 22 chars.
    
    [CONTENT RULES]
    1. **Language:** Korean ONLY. No Chinese, No Vietnamese.
    2. **Tone:** Trendy, Banmal. No cheap slang (ã…‹ã…‹, ã… ã… ).
    3. **Length (Excluding Spaces):** Exactly **45~48 characters**.
    4. **Content:** Don't just say "Watch it". Mention a specific conflict, romance, or event from the [News Data].
    
    [User's Past Data (Style Ref)]
    {context_raw}
    
    [User Request]
    {custom_instruction}

    [Output Format]
    - CSV format with '|' separator.
    - Columns: Category | Campaign | Target | Title | Body
    - **Language:** Korean ONLY.

    **Output ONLY the data rows.**
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7, 
            max_tokens=3000,
            top_p=1,
            stream=False,
            stop=None,
        )
        return completion.choices[0].message.content, "llama-3.3-70b"

    except Exception as e:
        raise Exception(f"Groq API ì˜¤ë¥˜: {str(e)}")

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: ë‚˜ëŠ”SOLO (ë˜ëŠ” í™˜ìŠ¹ì—°ì• 4)")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")
col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: íŒ©íŠ¸ ê¸°ë°˜ìœ¼ë¡œ í˜¸ê¸°ì‹¬ ìê·¹")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        # [ì¤‘ìš”] ì‚¬ìš©ìê°€ ëˆˆìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆê²Œ ë‰´ìŠ¤ ê²°ê³¼ë¥¼ ë¨¼ì € ë³´ì—¬ì¤Œ
        status_box.write("ğŸ” ë„¤ì´ë²„ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        search_info = get_naver_search(keyword)
        
        # ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì—ëŸ¬ì¸ì§€ í™•ì¸
        if "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" in search_info or "ì—ëŸ¬" in search_info:
            st.error("âš ï¸ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. AIê°€ ë‚´ìš©ì„ ì§€ì–´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.text_area("ê²€ìƒ‰ ìƒíƒœ", search_info)
        else:
            st.success("âœ… ìµœì‹  íŠ¸ë Œë“œ ì •ë³´ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
            with st.expander("ğŸ“° AIê°€ ì½ì€ ë‰´ìŠ¤ ë‚´ìš© í™•ì¸"):
                st.text(search_info) # ë‰´ìŠ¤ê°€ ì œëŒ€ë¡œ ê¸í˜”ëŠ”ì§€ í™•ì¸
        
        status_box.write("ğŸ“š ì‹œíŠ¸ ìŠ¤íƒ€ì¼ í•™ìŠµ ì¤‘...")
        context_raw = get_raw_sheet_text(sheet_id_input, sheet_gid_input)
        
        status_box.write("âš¡ Groq ì—”ì§„ ê°€ë™ (íŒ©íŠ¸ì²´í¬ & ì™¸êµ­ì–´ í•„í„°)...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            raw_text, used_model = generate_copy_groq(FIXED_API_KEY, context_raw, keyword, search_info, config)
            
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            lines = clean_csv.split('\n')
            
            data_rows = []
            for line in lines:
                if line.count('|') >= 3:
                    parts = line.split('|')
                    if 'ëŒ€ë¶„ë¥˜' in parts[0] or 'Category' in parts[0] or 'ë¶„ë¥˜' in parts[0]:
                        continue
                    data_rows.append(parts)
            
            fixed_columns = ["ëŒ€ë¶„ë¥˜", "ìº í˜ì¸", "íƒ€ê²Ÿ", "ì œëª©", "ë‚´ìš©"]
            
            if data_rows:
                safe_data = []
                for row in data_rows:
                    if len(row) >= 5:
                        safe_data.append(row[:5])
                    else:
                        safe_data.append(row + [""] * (5 - len(row)))
                        
                df = pd.DataFrame(safe_data, columns=fixed_columns)
            else:
                raise Exception("ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # í›„ì²˜ë¦¬
            if 'ë‚´ìš©' in df.columns:
                df['ë‚´ìš©'] = df['ë‚´ìš©'].apply(clean_and_format_legal_text)
            
            if 'ì œëª©' in df.columns:
                df['ì œëª©'] = df['ì œëª©'].apply(lambda x: str(x).strip()[:22])

            status_box.update(label=f"âœ… ì™„ë£Œ!", state="complete", expanded=False)
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
