import streamlit as st
import pandas as pd
from groq import Groq
import requests
from bs4 import BeautifulSoup
import io
import re
import csv
import random

# --- ğŸ”’ [API í‚¤ ì„¤ì •] ---
part1 = "gsk_lIDRWFZfRKNye7Il5egq"
part2 = "WGdyb3FY5WLFI3NtD9NB70RLy6uk4Mce"
FIXED_API_KEY = part1 + part2
FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (News Crawler Fix)")
st.markdown("ë„¤ì´ë²„ ë³´ì•ˆ ìš°íšŒ(Stealth Mode) + ë‰´ìŠ¤ íŒ©íŠ¸ì²´í¬ ê¸°ëŠ¥ ì ìš©")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY.startswith("gsk_"):
        st.success("âœ… Groq API Key ì—°ê²°ë¨")
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹°: í…ìŠ¤íŠ¸ ì •ì œ ---
def clean_and_format_legal_text(text):
    if not isinstance(text, str): return str(text)
    
    # 1. ì¤‘ë³µ ë²•ì  ë¬¸êµ¬ ì œê±°
    text = text.replace("(ê´‘ê³ )", "").replace("*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½", "")
    text = text.replace('"', '').replace("'", "")
    
    # 2. ì™¸êµ­ì–´ ì œê±° (ì´ëª¨ì§€, í•œê¸€, ìˆ«ì, ì˜ì–´, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ ìœ ì§€)
    # ë² íŠ¸ë‚¨ì–´, í•œì ë“± ì œê±°
    foreign_pattern = re.compile(r'[\u4E00-\u9FFF\u00C0-\u024F\u1E00-\u1EFF\u0600-\u06FF\u0400-\u04FF]+')
    text = foreign_pattern.sub('', text)
    
    # 3. ê³µë°± ì •ë¦¬
    text = text.strip()
    
    # 4. ë²•ì  ë¬¸êµ¬ ë¶€ì°©
    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ---
def get_raw_sheet_text(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        response = requests.get(url)
        response.encoding = 'utf-8'
        
        f = io.StringIO(response.text)
        reader = csv.reader(f)
        all_rows = list(reader)
        
        if len(all_rows) < 2: return "ë°ì´í„° ì—†ìŒ"
        
        learned_data = []
        recent_rows = all_rows[1:][-300:] # ìµœì‹  300ê°œ
        
        if len(recent_rows) > 60:
            target_rows = random.sample(recent_rows, 60)
        else:
            target_rows = recent_rows
        
        for row in target_rows:
            clean_row = [cell.strip() for cell in row if cell.strip()]
            if len(clean_row) >= 2:
                if len("".join(clean_row)) > 20:
                    row_str = " | ".join(clean_row)
                    learned_data.append(row_str)
        
        return "\n".join(learned_data)
    except Exception as e:
        return f"Error: {str(e)}"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë³´ì•ˆ ìš°íšŒ ê°•í™”) ---
def get_naver_search(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=1"
        
        # [í•µì‹¬] ì§„ì§œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ëŠ” í—¤ë” ì •ë³´ (User-Agent, Referer ë“±)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Referer': 'https://www.naver.com/',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        
        # ì ‘ì† ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
        if response.status_code != 200:
            return f"ë„¤ì´ë²„ ì ‘ì† ì°¨ë‹¨ë¨ (Status: {response.status_code})"
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        news_list = []
        # ë‰´ìŠ¤ 5ê°œ ê¸ì–´ì˜´ (ì œëª© + ìš”ì•½ë¬¸)
        # í´ë˜ìŠ¤ëª…ì´ ë°”ë€” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜ˆì™¸ì²˜ë¦¬
        items = soup.select(".news_area")
        if not items:
            return "ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (HTML êµ¬ì¡° ë³€ê²½ ë˜ëŠ” ê²€ìƒ‰ì–´ ë¬¸ì œ)"
            
        for item in items[:5]:
            title_tag = item.select_one('.news_tit')
            desc_tag = item.select_one('.news_dsc')
            
            if title_tag and desc_tag:
                title = title_tag.get_text()
                desc = desc_tag.get_text()
                news_list.append(f"Title: {title}\nSummary: {desc}")
            
        result = "\n---\n".join(news_list)
        return result if result else "ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
        
    except Exception as e:
        return f"í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì—ëŸ¬: {str(e)}"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: Groq í˜¸ì¶œ ---
def generate_copy_groq(api_key, context_raw, keyword, info, user_config):
    client = Groq(api_key=api_key)
    
    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    prompt = f"""
    Role: Professional Viral Marketing Copywriter (Korea).
    
    [YOUR MISSION]
    Create 10 marketing messages for '{keyword}'.
    
    [SOURCE OF TRUTH - NEWS DATA]
    **You MUST use the information below.** If this data contains specific details (names, dates, plot), USE THEM.
    **Do NOT invent facts.**
    
    [News Data]
    {info}
    
    [STRICT TITLE FORMAT]
    **[Emoji] <{keyword}> [Trend/News Hook]**
    - Example: ğŸ’˜ <ë‚˜ëŠ”ì†”ë¡œ> 23ê¸° ê²°í˜¼ ì»¤í”Œ íƒ„ìƒ?
    - Keep under 22 chars.
    
    [CONTENT RULES]
    1. **Language:** Korean ONLY. No Chinese, No Vietnamese.
    2. **Tone:** Trendy, Banmal. No cheap slang (ã…‹ã…‹, ã… ã… ).
    3. **Length (Excluding Spaces):** Exactly **45~48 characters**.
    4. **Content:** Don't just say "Watch it". Mention a specific conflict, romance, or event from the [News Data].
    
    [User's Past Data (Style Ref)]
    {context_raw}
    
    [User Request]
    {custom_instruction}

    [Output Format]
    - CSV format with '|' separator.
    - Columns: Category | Campaign | Target | Title | Body
    - **Language:** Korean ONLY.

    **Output ONLY the data rows.**
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7, 
            max_tokens=3000,
            top_p=1,
            stream=False,
            stop=None,
        )
        return completion.choices[0].message.content, "llama-3.3-70b"

    except Exception as e:
        raise Exception(f"Groq API ì˜¤ë¥˜: {str(e)}")

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: ë‚˜ëŠ”SOLO (ë˜ëŠ” í™˜ìŠ¹ì—°ì• 4)")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")
col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: íŒ©íŠ¸ ê¸°ë°˜ìœ¼ë¡œ í˜¸ê¸°ì‹¬ ìê·¹")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        status_box.write("ğŸ” ë„¤ì´ë²„ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ (ë³´ì•ˆ ìš°íšŒ ì‹œë„)...")
        search_info = get_naver_search(keyword)
        
        # ë‰´ìŠ¤ ìƒíƒœ í™•ì¸ ì°½ (ë””ë²„ê¹…ìš©)
        if "ì°¨ë‹¨ë¨" in search_info or "ì—ëŸ¬" in search_info:
            status_box.write("âš ï¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ì ì‹œ í›„ ì´ìš©í•´ì£¼ì„¸ìš”.")
            st.error(search_info)
        elif "ê²°ê³¼ ì—†ìŒ" in search_info:
             status_box.write("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            status_box.write("âœ… ìµœì‹  ë‰´ìŠ¤ í™•ë³´ ì™„ë£Œ!")
            with st.expander("ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë°ì´í„° ë³´ê¸°"):
                st.text(search_info)
        
        status_box.write("ğŸ“š ì‹œíŠ¸ ìŠ¤íƒ€ì¼ í•™ìŠµ ì¤‘...")
        context_raw = get_raw_sheet_text(sheet_id_input, sheet_gid_input)
        
        status_box.write("âš¡ Groq ì—”ì§„ ê°€ë™ (íŒ©íŠ¸ì²´í¬ & ì™¸êµ­ì–´ í•„í„°)...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            raw_text, used_model = generate_copy_groq(FIXED_API_KEY, context_raw, keyword, search_info, config)
            
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            lines = clean_csv.split('\n')
            
            data_rows = []
            for line in lines:
                if line.count('|') >= 3:
                    parts = line.split('|')
                    if 'ëŒ€ë¶„ë¥˜' in parts[0] or 'Category' in parts[0] or 'ë¶„ë¥˜' in parts[0]:
                        continue
                    data_rows.append(parts)
            
            fixed_columns = ["ëŒ€ë¶„ë¥˜", "ìº í˜ì¸", "íƒ€ê²Ÿ", "ì œëª©", "ë‚´ìš©"]
            
            if data_rows:
                safe_data = []
                for row in data_rows:
                    if len(row) >= 5:
                        safe_data.append(row[:5])
                    else:
                        safe_data.append(row + [""] * (5 - len(row)))
                        
                df = pd.DataFrame(safe_data, columns=fixed_columns)
            else:
                raise Exception("ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # í›„ì²˜ë¦¬
            if 'ë‚´ìš©' in df.columns:
                df['ë‚´ìš©'] = df['ë‚´ìš©'].apply(clean_and_format_legal_text)
            
            if 'ì œëª©' in df.columns:
                df['ì œëª©'] = df['ì œëª©'].apply(lambda x: str(x).strip()[:22])

            status_box.update(label=f"âœ… ì™„ë£Œ!", state="complete", expanded=False)
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
