import streamlit as st
import pandas as pd
from groq import Groq
import requests
from bs4 import BeautifulSoup
import io
import re
import csv
import random

# --- ğŸ”’ [API í‚¤ ì„¤ì •] ---
part1 = "gsk_lIDRWFZfRKNye7Il5egq"
part2 = "WGdyb3FY5WLFI3NtD9NB70RLy6uk4Mce"
FIXED_API_KEY = part1 + part2
FIXED_SHEET_ID = '1rZ4T2aiIU0OsKjMh-gX85Y2OrNoX8YzZI2AVE7CJOMw'
# -------------------------

st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ AI ë§ˆì¼€íŒ… ì¹´í”¼ ìƒì„±ê¸° (Title Fix)")
st.markdown("ì œëª© í’ˆì§ˆ ê°•í™”(ë‹¨ë‹µí˜• ê¸ˆì§€) + ê³µë°± ì œì™¸ 62ì ë³¸ë¬¸ + ìµœì í™” í•™ìŠµ")

# --- ğŸ‘ˆ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    if FIXED_API_KEY.startswith("gsk_"):
        st.success("âœ… Groq API Key ì—°ê²°ë¨")
    
    sheet_id_input = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ ID", value=FIXED_SHEET_ID)
    sheet_gid_input = st.text_input("ì‹œíŠ¸ GID (íƒ­ ë²ˆí˜¸)", value="0")

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹°: í…ìŠ¤íŠ¸ ì •ì œ ---
def clean_and_format_legal_text(text):
    if not isinstance(text, str): return str(text)
    
    # 1. ì¤‘ë³µ ë²•ì  ë¬¸êµ¬ ì œê±°
    text = text.replace("(ê´‘ê³ )", "").replace("*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½", "")
    text = text.replace('"', '').replace("'", "")
    
    # 2. ì €í’ˆì§ˆ ìŠ¬ë­ ì‚­ì œ
    text = text.replace("ã…‹ã…‹", "").replace("ã…ã…", "").replace("ã… ã… ", "").replace("ã„·ã„·", "")
    
    # 3. ì™¸êµ­ì–´ ì œê±°
    foreign_pattern = re.compile(r'[\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF\u0600-\u06FF]+')
    text = foreign_pattern.sub('', text)
    
    # 4. ê³µë°± ì •ë¦¬
    text = text.strip()
    
    # 5. ë²•ì  ë¬¸êµ¬ ë¶€ì°©
    return f"(ê´‘ê³ ) {text}\n*ìˆ˜ì‹ ê±°ë¶€:ì„¤ì •>ë³€ê²½"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§) ---
def get_raw_sheet_text(sheet_id, gid):
    try:
        url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'
        response = requests.get(url)
        response.encoding = 'utf-8'
        
        f = io.StringIO(response.text)
        reader = csv.reader(f)
        all_rows = list(reader)
        
        if len(all_rows) < 2: return "ë°ì´í„° ì—†ìŒ"
        
        learned_data = []
        recent_rows = all_rows[1:][-300:]
        
        # 300ê°œ ì¤‘ 60ê°œ ëœë¤ ì¶”ì¶œ (í† í° ìµœì í™”)
        if len(recent_rows) > 60:
            target_rows = random.sample(recent_rows, 60)
        else:
            target_rows = recent_rows
        
        for row in target_rows:
            clean_row = [cell.strip() for cell in row if cell.strip()]
            if len(clean_row) >= 2:
                if len("".join(clean_row)) > 15:
                    row_str = " | ".join(clean_row)
                    learned_data.append(row_str)
        
        return "\n".join(learned_data)
    except Exception as e:
        return f"Error: {str(e)}"

# --- ğŸ”§ í•µì‹¬ í•¨ìˆ˜: Groq í˜¸ì¶œ (ì œëª© í”„ë¡¬í”„íŠ¸ ëŒ€ìˆ˜ìˆ ) ---
def generate_copy_groq(api_key, context_raw, keyword, info, user_config):
    client = Groq(api_key=api_key)
    
    custom_instruction = ""
    if user_config['target']: custom_instruction += f"- íƒ€ê²Ÿ: {user_config['target']}\n"
    if user_config['note']: custom_instruction += f"- ìš”ì²­ì‚¬í•­: {user_config['note']}\n"

    prompt = f"""
    Role: You are a Professional Viral Marketing Copywriter (Target: Korea).
    
    [YOUR MISSION]
    Create 10 marketing messages for '{keyword}'.
    
    [TITLE RULES - VERY IMPORTANT]
    Format: **[Emoji] <{keyword}> [Catchy Phrase]**
    1. **NO Single Words:** NEVER write titles like "<{keyword}> ë‚¨ì", "<{keyword}> ë²•ë¥ ", "<{keyword}> ì¶”ì²œ".
    2. **Use Details:** You MUST use the [Trend Info] or specific details in the title. (e.g., Actor's name, 'Released Today', 'Shocking Twist').
    3. **Bad Examples (DON'T DO THIS):**
       - ğŸ‘® <í”„ë¡œë³´ë…¸> ë²•ì •ë¬¼ (Too simple)
       - ğŸ“º <í”„ë¡œë³´ë…¸> ë‚¨ì (Boring)
       - ğŸ”¥ <í™˜ìŠ¹ì—°ì• > ì—°ì•  (Meaningless)
    4. **Good Examples (DO THIS):**
       - ğŸ‘® <í”„ë¡œë³´ë…¸> ì •ê²½í˜¸ê°€ ëŒì•„ì™”ë‹¤!
       - ğŸ <í”„ë¡œë³´ë…¸> ì†ë¬¼ ë³€í˜¸ì‚¬ì˜ ë°˜ë€
       - ğŸ’˜ <í™˜ìŠ¹ì—°ì• > Xì™€ ì¬íšŒí•˜ëŠ” ë‚ 
    5. **Length:** Keep the total length under 22 characters.
    
    [CONTENT RULES]
    1. **Tone:** Casual (Banmal) or Noun-ending. NO 'ã…‹ã…‹', 'ã… ã… '.
    2. **Length (Excluding Spaces):** Write exactly **45~48 characters** (excluding spaces).
    3. **Mimic:** Learn patterns from [User's Past Data].
    
    [User's Past Data (Sampled)]
    {context_raw}
    
    [Trend Info (Use this for Titles)]
    {info}

    [User Request]
    {custom_instruction}

    [Output Format]
    - CSV format with '|' separator.
    - Columns: Category | Campaign | Target | Title | Body
    - **Language:** Korean ONLY.

    **Output ONLY the data rows.**
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8, # ì°½ì˜ì„±ì„ ìœ„í•´ 0.8ë¡œ ì•½ê°„ ìƒí–¥
            max_tokens=3000,
            top_p=1,
            stream=False,
            stop=None,
        )
        return completion.choices[0].message.content, "llama-3.3-70b"

    except Exception as e:
        raise Exception(f"Groq API ì˜¤ë¥˜: {str(e)}")

# --- (ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜) ---
def get_naver_search(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=1"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        news = []
        for item in soup.select(".news_area")[:3]:
            title = item.select_one('.news_tit').get_text()
            desc = item.select_one('.news_dsc').get_text()
            # AIì—ê²Œ ë” ë§ì€ ì¬ë£Œë¥¼ ì£¼ê¸° ìœ„í•´ ì œëª©+ìš”ì•½ í•¨ê»˜ ì „ë‹¬
            news.append(f"- {title} ({desc})") 
        return "\n".join(news) if news else ""
    except: return ""

# --- ì‹¤í–‰ë¶€ ---
col1, col2 = st.columns([2, 1])
with col1:
    keyword = st.text_input("ğŸ“¢ í™ë³´í•  ì£¼ì œ", placeholder="ì˜ˆ: í”„ë¡œë³´ë…¸")
with col2:
    campaign = st.text_input("ğŸ”– ìº í˜ì¸ëª…", placeholder="ì˜ˆ: ëŸ°ì¹­ì•Œë¦¼")
col3, col4 = st.columns([1, 1])
with col3:
    target = st.text_input("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •", placeholder="ì˜ˆ: 2030 ì—¬ì„±")
with col4:
    note = st.text_input("ğŸ“ ìš”ì²­ì‚¬í•­", placeholder="ì˜ˆ: í˜¸ê¸°ì‹¬ ìê·¹")

if st.button("ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘", type="primary"):
    if not keyword:
        st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        status_box = st.status("ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
        
        status_box.write(f"ğŸ” ì‹œíŠ¸ ë°ì´í„° ìƒ˜í”Œë§ & ë‰´ìŠ¤ ë¶„ì„ ì¤‘...")
        search_info = get_naver_search(keyword)
        context_raw = get_raw_sheet_text(sheet_id_input, sheet_gid_input)
        
        status_box.write("âš¡ Groq ì—”ì§„ ê°€ë™ (ì œëª© í€„ë¦¬í‹° UP)...")
        try:
            config = {"campaign": campaign, "target": target, "note": note}
            
            raw_text, used_model = generate_copy_groq(FIXED_API_KEY, context_raw, keyword, search_info, config)
            
            clean_csv = raw_text.replace('```csv', '').replace('```', '').strip()
            lines = clean_csv.split('\n')
            
            data_rows = []
            for line in lines:
                if line.count('|') >= 3:
                    parts = line.split('|')
                    if 'ëŒ€ë¶„ë¥˜' in parts[0] or 'Category' in parts[0] or 'ë¶„ë¥˜' in parts[0]:
                        continue
                    data_rows.append(parts)
            
            fixed_columns = ["ëŒ€ë¶„ë¥˜", "ìº í˜ì¸", "íƒ€ê²Ÿ", "ì œëª©", "ë‚´ìš©"]
            
            if data_rows:
                safe_data = []
                for row in data_rows:
                    if len(row) >= 5:
                        safe_data.append(row[:5])
                    else:
                        safe_data.append(row + [""] * (5 - len(row)))
                        
                df = pd.DataFrame(safe_data, columns=fixed_columns)
            else:
                raise Exception("ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # í›„ì²˜ë¦¬
            if 'ë‚´ìš©' in df.columns:
                df['ë‚´ìš©'] = df['ë‚´ìš©'].apply(clean_and_format_legal_text)
            
            if 'ì œëª©' in df.columns:
                # 22ì ì œí•œì€ ìœ ì§€í•˜ë˜, ë‚´ìš©ì´ ì•Œì°¨ê²Œ ë“¤ì–´ì˜¤ë„ë¡
                df['ì œëª©'] = df['ì œëª©'].apply(lambda x: str(x).strip()[:22])

            status_box.update(label=f"âœ… ì™„ë£Œ!", state="complete", expanded=False)
            st.subheader("ğŸ“Š ìƒì„±ëœ ë§ˆì¼€íŒ… ê¸°íšì•ˆ")
            st.dataframe(df, use_container_width=True)
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{keyword}_plan.csv", "text/csv")
            
        except Exception as e:
            status_box.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì—ëŸ¬ ë‚´ìš©: {e}")
